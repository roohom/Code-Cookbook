

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>20. PySpark On Yarn &mdash; Code-Cookbook 0.1 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="21. 简单(常用)数据结构" href="SimpleDataStruct.html" />
    <link rel="prev" title="19. PySpark" href="PySpark.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Code-Cookbook
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">大数据</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Bigdata/index.html">Bigdata</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bigdata%20Tools/index.html">Bigdata Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">博客</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Blogs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="0904%E6%A8%A1%E6%8B%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86.html">1. 面试题整理</a></li>
<li class="toctree-l2"><a class="reference internal" href="1008%E6%A8%A1%E6%8B%9F%E9%9D%A2%E8%AF%95%E6%95%B4%E7%90%86.html">2. 实时存储NoSQL面试</a></li>
<li class="toctree-l2"><a class="reference internal" href="Annotation.html">3. 元注解</a></li>
<li class="toctree-l2"><a class="reference internal" href="Annotation.html#id2">4. 注解解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="Closure%26Currying.html">5. Scala函数中闭包(Closure)和柯里化(Currying)</a></li>
<li class="toctree-l2"><a class="reference internal" href="Collection.html">6. 集合</a></li>
<li class="toctree-l2"><a class="reference internal" href="Collection.html#id9">7. 简单(常用)数据结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="Commands.html">8. Commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="EOF.html">9. EOF</a></li>
<li class="toctree-l2"><a class="reference internal" href="Git.html">10. Git问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hadoop%20distcp.html">11. Hadoop distcp</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hive%20SQL50%E9%A2%98%E8%AE%B0%E5%BD%95.html">12. Hive SQL50题记录</a></li>
<li class="toctree-l2"><a class="reference internal" href="IO%E6%B5%81.html">13. <code class="docutils literal notranslate"><span class="pre">IO</span> <span class="pre">Stream</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="Java%20Cookbook.html">14. JAVA Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="Java8%20Stream%28%29.html">15. Java8 Stream API</a></li>
<li class="toctree-l2"><a class="reference internal" href="Java_Maven.html">16. Maven</a></li>
<li class="toctree-l2"><a class="reference internal" href="Java_OOP.html">17. Java_OOP</a></li>
<li class="toctree-l2"><a class="reference internal" href="Java%E4%B8%ADSocket%E5%8F%91%E9%80%81%E6%96%87%E4%BB%B6%E8%87%B3%E6%9C%8D%E5%8A%A1%E7%AB%AF.html">18. 使用Java在服务端和客户端之间传送文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="PySpark.html">19. PySpark</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">20. PySpark On Yarn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">20.1. 废话说在前</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pyspark-shell">20.2. PySpark shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">20.3. 万全方案</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">20.3.1. 先决条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">20.3.2. 提交任务</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">20.3.3. 命令说明</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#run">20.4. RUN起来！</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="SimpleDataStruct.html">21. 简单(常用)数据结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="Socket.html">22. Socket</a></li>
<li class="toctree-l2"><a class="reference internal" href="Spark%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1RSA%20premaster%20secret%20error.html">23. Spark提交任务RSA premaster secret error</a></li>
<li class="toctree-l2"><a class="reference internal" href="Springboot%E6%95%B4%E5%90%88Spark%2C%20%E6%9C%AC%E5%9C%B0%E3%80%81%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.html">24. Springboot整合Spark, 本地、集群部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="Vim%E6%9F%A5%E6%89%BE%E5%92%8C%E6%9B%BF%E6%8D%A2%E5%91%BD%E4%BB%A4.html">25. Vim查找和替换命令</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell%E8%84%9A%E6%9C%AC%E6%97%A5%E6%9C%9F%E9%80%92%E5%A2%9E%28%E8%B5%B7%E6%AD%A2%E6%97%A5%E6%9C%9F%E5%86%85%E9%80%92%E5%A2%9E%29.html">26. Shell脚本日期递增(起止日期内递增)</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%85%B3%E4%BA%8EKudu%20Upsert%E5%88%97%E7%9A%84%E9%97%AE%E9%A2%98.html">27. 关于Kudu Upsert列的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%85%B3%E4%BA%8EKudu%E5%88%97%E7%9A%84%E9%A1%BA%E5%BA%8F%E7%9A%84%E4%BF%AE%E6%94%B9.html">28. 关于Kudu列的顺序的修改</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%8F%AF%E8%83%BD%E6%9C%89%E7%94%A8%E7%9A%84%E5%AD%A6%E4%B9%A0%E9%93%BE%E6%8E%A5.html">29. 可能有用的学习链接</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%8F%AF%E8%83%BD%E6%9C%89%E7%94%A8%E7%9A%84%E5%AD%A6%E4%B9%A0%E9%93%BE%E6%8E%A5.html#hive-orc">30. Hive - ORC 文件存储格式</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%A4%9A%E7%BA%BF%E7%A8%8B.html">31. 多线程</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%B0%86Spark%20DataFrame%E4%B8%AD%E7%9A%84%E6%95%B0%E5%80%BC%E5%8F%96%E5%87%BA.html">32. 将Spark DataFrame中的数值取出</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E6%89%93%E5%8D%B0%E6%9C%AC%E6%9C%BAIP.html">33. 打印本机IP</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E6%9C%AC%E5%9C%B0%E8%BF%9E%E6%8E%A5%E9%9C%80%E8%A6%81Kerberos%E8%AE%A4%E8%AF%81%E7%9A%84Hive.html">34. 本地连接需要Kerberos认证的Hive</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%E9%97%AE%E9%A2%98.html">35. 生产者消费者模型问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html">36. JAVA设计模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html#continuing">37. Continuing…</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%85%AD%E5%A4%A7%E5%8E%9F%E5%88%99.html">38. 设计模式六大原则</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E6%A2%B3%E7%90%86.html">39. 面向对象知识点梳理</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%90%84%E7%A7%8D%E5%85%B3%E7%B3%BB.html">40. Java OOP防脱发指南</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">大数据辅助工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Auxiliary%20tools/index.html">Auxiliary tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SQL相关</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../SQL/index.html">SQL</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Code-Cookbook</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Blogs</a> &raquo;</li>
        
      <li><span class="section-number">20. </span>PySpark On Yarn</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/Blog Here/PySparkOnYarn.md.txt" rel="nofollow"> 查看页面源码</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pyspark-on-yarn">
<h1><span class="section-number">20. </span>PySpark On Yarn<a class="headerlink" href="#pyspark-on-yarn" title="永久链接至标题">¶</a></h1>
<div class="section" id="id1">
<h2><span class="section-number">20.1. </span>废话说在前<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<p>Spark是高效的内存计算引擎，可以通过其<code class="docutils literal notranslate"><span class="pre">spark-submit</span></code>命令将任务提交到Yarn上运行，命令大致类似于如下:</p>
<div class="highlight-SHELL notranslate"><div class="highlight"><pre><span></span>$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster <span class="o">[</span>options<span class="o">]</span> &lt;app jar&gt; <span class="o">[</span>app options<span class="o">]</span>
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi <span class="se">\</span>
    --master yarn <span class="se">\</span>
    --deploy-mode cluster <span class="se">\</span>
    --driver-memory 4g <span class="se">\</span>
    --executor-memory 2g <span class="se">\</span>
    --executor-cores <span class="m">1</span> <span class="se">\</span>
    --queue thequeue <span class="se">\</span>
    examples/jars/spark-examples*.jar <span class="se">\</span>
    <span class="m">10</span>
</pre></div>
</div>
<p>并且Spark也有Python应用编程接口，可以使用Python进行快速的Spark应用开发，在数据分析领域，那叫一个快啊，上手极其轻松。</p>
<p>如果数据量小，跑一跑Spark Local也就好了，代码类似于如下:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span><span class="o">=</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="n">SparkOnLocal</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT 1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
<p>当程序运行的时候会在本地启动Spark服务，具体的安装和部署以及简单的应用编写详见我的另一篇博客<a class="reference external" href="https://code-cookbook.readthedocs.io/zh_CN/main/Blog%20Here/PySpark.html">PySpark</a></p>
<p>那么问题来了，当数据量很大的时候，本地机器的资源已经不能胜任开发和分析的工作，怎么办呢？这时候就需要使用PySpark On Yarn了，将我们的PySpark程序提交到Yarn上运行，话不多说，下面开始。</p>
</div>
<div class="section" id="pyspark-shell">
<h2><span class="section-number">20.2. </span>PySpark shell<a class="headerlink" href="#pyspark-shell" title="永久链接至标题">¶</a></h2>
<p>和spark-shell一样，pyspark也有shell，如果安装了spark，直接在命令行输入pyspark即可进入pyspark的命令行，SparkSession便已经实例化好了。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &#39;_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.0-cdh6.1.1
      /_/

Using Python version 2.7.5 (default, Nov 16 2020 22:23:17)
SparkSession available as &#39;spark&#39;.
</pre></div>
</div>
<p>可以看到，使用的是默认的Python2.7.5的版本，要知道，Python2.7.5已经停止维护了，并且现在大部分的第三方库和应用都是python3编写的，Python3和Python2的语法上也有显著的差别，最显然的当然就是print了，dddd</p>
<p>如果在不同的机器上有着不同的python版本，那么当运行pyspark任务的时候会抛出python版本不一致的异常，提示你DRIVER和WORKER上的Python版本不一致，需要正确设置<code class="docutils literal notranslate"><span class="pre">PYSPARK_PYTHON</span></code>和<code class="docutils literal notranslate"><span class="pre">PYSPARK_DRIVER_PYTHON</span></code>这两个变量</p>
</div>
<div class="section" id="id2">
<h2><span class="section-number">20.3. </span>万全方案<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>上面抛出的Python版本不一致的问题，你可能会想，直接在全部的机器上安装Python3不就好了，是的，这样问题确实可以解决，但是，在现有的大数据集群环境中，每台节点安装相同版本的Python固然可行，但是耗时耗力，有没有一种万全的方案，让Pyspark使用高版本的Python并且可以不在节点上安装Python3环境呢？</p>
<p><strong>办法是有的！</strong></p>
<p><strong>我们可以通过将Python虚拟环境打包，将其上传到HDFS上，当提交我们的任务时，Spark的worker节点会自动加载该虚拟环境，使用其中的Python环境运行我们的<code class="docutils literal notranslate"><span class="pre">.py</span></code>程序</strong></p>
<div class="section" id="id3">
<h3><span class="section-number">20.3.1. </span>先决条件<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>将我们的Python3虚拟环境打包，使用<code class="docutils literal notranslate"><span class="pre">.zip</span></code>的格式上传到HDFS，推荐使用Conda打包，此步骤可以去百度搜索看看。</p>
<ul class="simple">
<li><p>1.以miniconda为例</p></li>
<li><p>安装好miniconda</p></li>
<li><p>使用conda create -n $myenv_name python=3.6 并用python=3.6来指定对应python环境的版本</p></li>
<li><p>在创建好的环境(在miniconda 安装目录的env文件夹下面)使用pip 安装好需要的包</p></li>
<li><p>使用zip 命令将 env文件夹下面对应$myenv_name的文件夹打包 该文件夹包含了所有的 环境所需的文件 打包后 发送到集群的各台机器上即可工作</p></li>
<li><p>在spark提交命令中 使用 –conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./PyEnv/py36/bin/python来指定对应的python指定文件 PyEnv 是将压缩包解压后的目录py36是$myenv_name python是对应环境下面的python可执行文件</p></li>
</ul>
</div>
<div class="section" id="id4">
<h3><span class="section-number">20.3.2. </span>提交任务<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>完整的提交命令如下:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>spark-submit <span class="se">\</span>
--master yarn <span class="se">\</span>
--deploy-mode cluster <span class="se">\</span>
--driver-memory 1g <span class="se">\</span>
--driver-cores <span class="m">2</span> <span class="se">\</span>
--num-executors <span class="m">3</span> <span class="se">\</span>
--executor-memory 5G <span class="se">\</span>
--conf spark.executor.pyspark.memory<span class="o">=</span>2G <span class="se">\</span>
--executor-cores <span class="m">4</span> <span class="se">\</span>
--conf spark.yarn.maxAppAttempts<span class="o">=</span><span class="m">1</span> <span class="se">\</span>
--conf spark.driver.maxResultSize<span class="o">=</span>2G <span class="se">\</span>
--conf spark.dynamicAllocation.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
--archives hdfs://nameservice1/tmp/pyenv/p36.zip#PyEnv <span class="se">\</span>
--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
--conf spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
--conf spark.executorEnv.PYSPARK_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
--conf spark.executorEnv.PYSPARK_DRIVER_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
./sample.py 
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">sample.py</span></code>的内容如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;PySparkOnYarn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT &#39;AAA&#39; AS AHA&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3><span class="section-number">20.3.3. </span>命令说明<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<ul>
<li><p>归档文件<code class="docutils literal notranslate"><span class="pre">--archives</span></code></p>
<blockquote>
<div><p>–archives ./py36.zip#PyEnv
这个参数的意思是将压缩包 zip文件分发到集群上,将压缩文件解压,解压后的文件全部放在 # 后面指定的文件夹下 PyEnv 这个目录下面,也就是说在代码中可以使用 PyEnv/xxx.txt 来读取压缩包中的xxx.txt文件,多个压缩文件使用逗号分隔符分割,如果压缩包里面有一个跟文件夹root_dir/,那么解压后将变成 PyEnv/root_dir</p>
</div></blockquote>
</li>
<li><p>一般资源文件<code class="docutils literal notranslate"><span class="pre">--files</span></code></p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">--files</span> <span class="pre">./config.json#my_config.json</span></code>
这个参数的意思是 将<code class="docutils literal notranslate"><span class="pre">config.json</span></code> 文件分发到集群上 之后使用<code class="docutils literal notranslate"><span class="pre">my_config.json</span></code>来访问这个文件 <code class="docutils literal notranslate"><span class="pre">#</span></code>后面相当于是文件的别名 文件表示使用逗号分隔符分割</p>
</div></blockquote>
</li>
<li><p>代码文件<code class="docutils literal notranslate"><span class="pre">--py-files</span></code></p>
<blockquote>
<div><p>有时候提交的pyspark python脚本文件不止一个 互相之间要引用 这时要
例如
–py-files ./feature.py
这个参数的意思是 将feature.py 文件分发到集群上 放在和主脚本在一起的代码目录下 这样就可以引用feature.py中的函数了 文件表示使用逗号分隔符分割</p>
</div></blockquote>
</li>
<li><p>下面这三个命令都是将Driver和Worker节点的Python环境设置为我们手动打包上传的Python环境</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">yarn</span><span class="o">.</span><span class="n">appMasterEnv</span><span class="o">.</span><span class="n">PYSPARK_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
<span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">yarn</span><span class="o">.</span><span class="n">appMasterEnv</span><span class="o">.</span><span class="n">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
<span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">executorEnv</span><span class="o">.</span><span class="n">PYSPARK_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
<span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">executorEnv</span><span class="o">.</span><span class="n">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
</pre></div>
</div>
</div>
</div>
<div class="section" id="run">
<h2><span class="section-number">20.4. </span>RUN起来！<a class="headerlink" href="#run" title="永久链接至标题">¶</a></h2>
<p>提交</p>
<p><img alt="image-20210809235223787" src="../_images/image-20210809235223787.png" /></p>
<p><img alt="image-20210809235343512" src="../_images/image-20210809235343512.png" /></p>
<p><img alt="image-20210809235407073" src="../_images/image-20210809235407073.png" /></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="SimpleDataStruct.html" class="btn btn-neutral float-right" title="21. 简单(常用)数据结构" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="PySpark.html" class="btn btn-neutral float-left" title="19. PySpark" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2020-2021, roohom.

    </p>
  </div>
    
    
    
    利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    
    由 <a href="https://readthedocs.org">Read the Docs</a>开发. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>