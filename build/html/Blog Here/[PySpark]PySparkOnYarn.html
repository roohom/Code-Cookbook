<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>43. [PySpark]PySpark On Yarn &mdash; Code-Cookbook 0.2 文档</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="44. [SQL]IN OR NOT IN , IS A PROBLEM" href="%5BSQL%5DSQLIn%26NotIn.html" />
    <link rel="prev" title="42. [Pyspark]PySpark" href="%5BPySpark%5DPySpark.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Code-Cookbook
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">大数据</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Bigdata/index.html">Bigdata</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Bigdata%20Tools/index.html">Bigdata Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">博客</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Blogs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Boxed%20Error.html">1. [Springboot x spark]java.util.concurrent.ExecutionException: Boxed Error</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BApollo%5DApollo%20Config%20Center.html">2. [Apollo]Apollo Config Center</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BConfluent%5DConfluent.html">3. [Confluent]Confluent快速上手</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5DCommdLine%2BSpringboot%2Bflink%E6%97%A0%E6%B3%95%E6%8C%87%E5%AE%9A%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%90%AF%E5%8A%A8.html">4. [Flink]CommdLine+Springboot+flink无法指定配置文件启动</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5DFlink-connector-http.html">5. [Flink]Flink-connector-http</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5DFlinkSource.html">6. [Flink]Flink Sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5DProcessFunction%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%EF%BC%8C%E6%8A%9B%E5%87%BAInvalidProgramException.html">7. [Flink]ProcessFunction无法使用，抛出InvalidProgramException</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5D%E4%BD%BF%E7%94%A8%E7%8A%B6%E6%80%81%E7%AE%97%E5%AD%90%E5%B0%86stream%E8%81%9A%E5%90%88%E8%BE%93%E5%87%BA.html">8. [Flink]使用状态算子将stream聚合输出</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5D%E5%A6%82%E4%BD%95%E6%9B%B4%E9%80%9A%E7%94%A8%E5%9C%B0%E5%B0%86Kafka%28%E6%88%96%E5%85%B6%E4%BB%96%29%E6%95%B0%E6%8D%AE%E8%90%BD%E5%9C%B0Hive%EF%BC%9F.html">9. [Flink]如何更通用地将Kafka(或其他)数据落地Hive？</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BFlink%5D%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%8F%E5%88%97%E5%8C%96%E6%B6%88%E8%B4%B9Kafka%E6%95%B0%E6%8D%AE.html">10. [Flink]自定义序列化消费Kafka数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BGit%5DGit.html">11. [Git]Git问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BGit%5D%E8%AF%AF%E5%9C%A8Master%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B9%B6commit%E6%97%A0%E6%B3%95push.html">12. [Git]误在Master分支开发并commit无法push</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BHadoop%5DHadoop%20distcp.html">13. [Hadoop]Hadoop distcp</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BHadoop%5D%E4%B8%80%E4%BA%9BHadoop%E9%97%AE%E9%A2%98.html">14. [Hadoop]一些Hadoop问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BHive%5DHive%E5%88%86%E5%8C%BA%E8%A1%A8%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E5%88%86%E5%8C%BA.html">15. [Hive]Hive分区表批量删除分区</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BHive%5D%E5%9C%A8%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%BD%AE%E6%B7%BB%E5%8A%A0%E5%AD%97%E6%AE%B5.html">16. [Hive]在指定位置添加字段</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BHive%5D%E5%A4%96%E9%83%A8%E8%A1%A8%E4%BF%AE%E6%94%B9%E4%B8%BA%E5%86%85%E9%83%A8%E8%A1%A8.html">17. [Hive]外部表修改为内部表</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BHive%5D%E6%9C%AC%E5%9C%B0%E8%BF%9E%E6%8E%A5%E9%9C%80%E8%A6%81Kerberos%E8%AE%A4%E8%AF%81%E7%9A%84Hive.html">18. [Hive]本地连接需要Kerberos认证的Hive</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJAVA%5DJava%20Cookbook.html">19. [JAVA]JAVA Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DAnnotation.html">20. [Java]元注解</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DAnnotation.html#id1">21. 注解解析</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DCollection.html">22. [Java]集合</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DCollection.html#id8">23. 简单(常用)数据结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DIO%E6%B5%81.html">24. [Java]<code class="docutils literal notranslate"><span class="pre">IO</span> <span class="pre">Stream</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DJava8%20Stream.html">25. [Java]Java8 Stream API</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DOOP.html">26. [Java]Java_OOP</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DSocket.html">27. [Java]Socket</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5DSocket%E5%8F%91%E9%80%81%E6%96%87%E4%BB%B6%E8%87%B3%E6%9C%8D%E5%8A%A1%E7%AB%AF.html">28. [Java]使用Java在服务端和客户端之间传送文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E4%B8%89%E7%A7%8D%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%E5%BA%94%E7%94%A8%E4%BA%8E%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%90%AF%E5%8A%A8.html">29. [Java]三种策略模式应用于服务的启动</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E5%A4%9A%E7%BA%BF%E7%A8%8B.html">30. [Java]多线程</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%E9%97%AE%E9%A2%98.html">31. [Java]生产者消费者模型问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E8%AE%A9%E9%A1%B9%E7%9B%AE%E9%A1%BA%E5%88%A9%E8%AF%BB%E5%8F%96resources%E7%9B%AE%E5%BD%95%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6.html">32. [Java]让项目顺利读取resources目录下的文件</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html">33. [Java]设计模式</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html#continuing">34. Continuing…</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%85%AD%E5%A4%A7%E5%8E%9F%E5%88%99.html">35. [Java]设计模式六大原则</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E6%A2%B3%E7%90%86.html">36. [Java]面向对象知识点梳理</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BJava%5D%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%90%84%E7%A7%8D%E5%85%B3%E7%B3%BB.html">37. [Java]OOP防脱发指南</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BKerberos%5DMessage%20stream%20modified%20%2841%29%E9%94%99%E8%AF%AF.html">38. [Kerberos]Message stream modified (41)错误</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BKudu%5D%E5%85%B3%E4%BA%8EKudu%20Upsert%E5%88%97%E7%9A%84%E9%97%AE%E9%A2%98.html">39. [Kudu]关于Kudu Upsert列的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BKudu%5D%E5%85%B3%E4%BA%8EKudu%E5%88%97%E7%9A%84%E9%A1%BA%E5%BA%8F%E7%9A%84%E4%BF%AE%E6%94%B9.html">40. [Kudu]关于Kudu列的顺序的修改</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BMongoDB%5DMongoDB%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2.html">41. [MongoDB]MongoDB基本查询</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BPySpark%5DPySpark.html">42. [Pyspark]PySpark</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">43. [PySpark]PySpark On Yarn</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">43.1. 废话说在前</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pyspark-shell">43.2. PySpark shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">43.3. 万全方案</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">43.3.1. 先决条件</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">43.3.2. 提交任务</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id5">43.3.3. 命令说明</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#run">43.4. RUN起来！</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="%5BSQL%5DSQLIn%26NotIn.html">44. [SQL]<code class="docutils literal notranslate"><span class="pre">IN</span></code> OR <code class="docutils literal notranslate"><span class="pre">NOT</span> <span class="pre">IN</span></code> , IS A PROBLEM</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSQL%5D%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%60create_time%60%E5%92%8C%60update_time%60.html">45. [SQL]业务数据库中的<code class="docutils literal notranslate"><span class="pre">create_time</span></code>和<code class="docutils literal notranslate"><span class="pre">update_time</span></code>分析时的问题</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSQL%5D%E4%B8%BA%E4%BB%80%E4%B9%88LEFT%20JOIN%E5%90%8E%E6%80%BB%E6%95%B0%E5%8D%B4%E4%B8%8E%E5%8F%B3%E8%A1%A8%E7%9A%84%E6%80%BB%E6%95%B0%E4%B8%80%E6%A0%B7%E4%BA%86%EF%BC%9F.html">46. [SQL]为什么LEFT JOIN后总数却与右表的总数一样了？</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSQL%5D%E6%B1%82%E7%94%A8%E6%88%B7%E4%BB%BB%E6%84%8F%E5%A4%A9%E8%BF%9E%E7%BB%AD%E7%99%BB%E5%BD%95%28%E6%AF%8F%E5%A4%A9%E4%B8%BA%E7%AC%AC%E5%A4%9A%E5%B0%91%E5%A4%A9%E8%BF%9E%E7%BB%AD%E7%99%BB%E5%BD%95%29.html">47. [SQL]求用户任意天连续登录(每天为第多少天连续登录)</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSQL%5D%E8%AE%A1%E7%AE%97%E6%8C%87%E5%AE%9A%E6%97%A5%E6%9C%9F%E7%9A%84%E5%B9%B4-%E5%91%A8%28%E4%B8%BA%E6%9F%90%E5%B9%B4%E7%9A%84%E7%AC%AC%E5%A4%9A%E5%B0%91%E5%91%A8%29.html">48. [SQL]计算指定日期的<strong>年-周</strong>(为某年的第多少周)</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BScala%5DClosure%26Currying.html">49. [Scala]函数中闭包(Closure)和柯里化(Currying)</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BShell%5DEOF.html">50. [Shell]EOF</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BShell%5Dshell%E8%84%9A%E6%9C%AC%E6%97%A5%E6%9C%9F%E9%80%92%E5%A2%9E%28%E8%B5%B7%E6%AD%A2%E6%97%A5%E6%9C%9F%E5%86%85%E9%80%92%E5%A2%9E%29.html">51. [Shell]Shell脚本日期递增(起止日期内递增)</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BShell%5D%E6%89%93%E5%8D%B0%E6%9C%AC%E6%9C%BAIP.html">52. [Shell]打印本机IP</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSparkStreaming%5D%E6%B6%88%E8%B4%B9kafka%E5%86%99%E5%85%A5Hive%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98.html">53. [SparkStreaming]消费kafka写入Hive失败的问题Lease timeout of 0 seconds expired</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpark%5DSparkSQL%20%E5%88%97%E8%BD%AC%E8%A1%8C%E7%9A%84%E4%B8%80%E7%A7%8D%E6%96%B9%E6%B3%95.html">54. [Spark]SparkSQL 列转行的一种方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpark%5DSparkSQLJDBC%E5%B9%B6%E5%8F%91%E8%BF%9E%E6%8E%A5%E8%AF%BB%E5%8F%96.html">55. [Spark]SparkSQL JDBC并发连接读取</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpark%5DSpark%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1RSA%20premaster%20secret%20error.html">56. [Spark]Spark提交任务RSA premaster secret error</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpark%5DSpringboot%E6%95%B4%E5%90%88Spark%2C%20%E6%9C%AC%E5%9C%B0%E3%80%81%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2.html">57. [Spark]Springboot整合Spark, 本地、集群部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpark%5D%E4%BD%BF%E7%94%A8Java%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AARow.html">58. [Spark]如何使用Java创建一个Row</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpark%5D%E5%B0%86Spark%20DataFrame%E4%B8%AD%E7%9A%84%E6%95%B0%E5%80%BC%E5%8F%96%E5%87%BA.html">59. [Spark]将Spark DataFrame中的数值取出</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BSpringboot%5DokHttp%E9%94%99%E8%AF%AFException%20in%20thread%20OkHttp%20Dispatcher%20java.lang.IllegalStateException%20closed.html">60. [Springboot]okHttp错误:<em>Exception</em> in thread “OkHttp Dispatcher” <em>java.lang.IllegalStateException</em>: closed</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5BVim%5D%E6%9F%A5%E6%89%BE%E5%92%8C%E6%9B%BF%E6%8D%A2%E5%91%BD%E4%BB%A4.html">61. [Vim]Vim查找和替换命令</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5Bdebezium%5D%E5%9C%A8%E5%90%AF%E5%8A%A8%E4%BB%BB%E5%8A%A1%E6%97%B6%E4%BC%A0%E5%85%A5SQL%E8%AF%AD%E5%8F%A5%E7%94%9F%E6%88%90Snapshot.html">62. [debezium]在启动任务时传入SQL语句生成Snapshot</a></li>
<li class="toctree-l2"><a class="reference internal" href="%5Bdebezium%5D%E7%83%AD%E4%BF%AE%E6%94%B9DebeziumMySQLConnector%E9%85%8D%E7%BD%AE.html">63. [debezium]热修改Debezium MySQL Connector配置</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">大数据辅助工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Auxiliary%20tools/index.html">Auxiliary tools</a></li>
</ul>
<p class="caption"><span class="caption-text">SQL相关</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../SQL/index.html">SQL</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Code-Cookbook</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Blogs</a> &raquo;</li>
      <li><span class="section-number">43. </span>[PySpark]PySpark On Yarn</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Blog Here/[PySpark]PySparkOnYarn.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pyspark-pyspark-on-yarn">
<h1><span class="section-number">43. </span>[PySpark]PySpark On Yarn<a class="headerlink" href="#pyspark-pyspark-on-yarn" title="永久链接至标题"></a></h1>
<section id="id1">
<h2><span class="section-number">43.1. </span>废话说在前<a class="headerlink" href="#id1" title="永久链接至标题"></a></h2>
<p>Spark是高效的内存计算引擎，可以通过其<code class="docutils literal notranslate"><span class="pre">spark-submit</span></code>命令将任务提交到Yarn上运行，命令大致类似于如下:</p>
<div class="highlight-SHELL notranslate"><div class="highlight"><pre><span></span>$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster <span class="o">[</span>options<span class="o">]</span> &lt;app jar&gt; <span class="o">[</span>app options<span class="o">]</span>
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi <span class="se">\</span>
    --master yarn <span class="se">\</span>
    --deploy-mode cluster <span class="se">\</span>
    --driver-memory 4g <span class="se">\</span>
    --executor-memory 2g <span class="se">\</span>
    --executor-cores <span class="m">1</span> <span class="se">\</span>
    --queue thequeue <span class="se">\</span>
    examples/jars/spark-examples*.jar <span class="se">\</span>
    <span class="m">10</span>
</pre></div>
</div>
<p>并且Spark也有Python应用编程接口，可以使用Python进行快速的Spark应用开发，在数据分析领域，那叫一个快啊，上手极其轻松。</p>
<p>如果数据量小，跑一跑Spark Local也就好了，代码类似于如下:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span><span class="o">=</span><span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="n">SparkOnLocal</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT 1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
<p>当程序运行的时候会在本地启动Spark服务，具体的安装和部署以及简单的应用编写详见我的另一篇博客<a class="reference external" href="https://code-cookbook.readthedocs.io/zh_CN/main/Blog%20Here/PySpark.html">PySpark</a></p>
<p>那么问题来了，当数据量很大的时候，本地机器的资源已经不能胜任开发和分析的工作，怎么办呢？这时候就需要使用PySpark On Yarn了，将我们的PySpark程序提交到Yarn上运行，话不多说，下面开始。</p>
</section>
<section id="pyspark-shell">
<h2><span class="section-number">43.2. </span>PySpark shell<a class="headerlink" href="#pyspark-shell" title="永久链接至标题"></a></h2>
<p>和spark-shell一样，pyspark也有shell，如果安装了spark，直接在命令行输入pyspark即可进入pyspark的命令行，SparkSession便已经实例化好了。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &#39;_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.0-cdh6.1.1
      /_/

Using Python version 2.7.5 (default, Nov 16 2020 22:23:17)
SparkSession available as &#39;spark&#39;.
</pre></div>
</div>
<p>可以看到，使用的是默认的Python2.7.5的版本，要知道，Python2.7.5已经停止维护了，并且现在大部分的第三方库和应用都是python3编写的，Python3和Python2的语法上也有显著的差别，最显然的当然就是print了，dddd</p>
<p>如果在不同的机器上有着不同的python版本，那么当运行pyspark任务的时候会抛出python版本不一致的异常，提示你DRIVER和WORKER上的Python版本不一致，需要正确设置<code class="docutils literal notranslate"><span class="pre">PYSPARK_PYTHON</span></code>和<code class="docutils literal notranslate"><span class="pre">PYSPARK_DRIVER_PYTHON</span></code>这两个变量</p>
</section>
<section id="id2">
<h2><span class="section-number">43.3. </span>万全方案<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<p>上面抛出的Python版本不一致的问题，你可能会想，直接在全部的机器上安装Python3不就好了，是的，这样问题确实可以解决，但是，在现有的大数据集群环境中，每台节点安装相同版本的Python固然可行，但是耗时耗力，有没有一种万全的方案，让Pyspark使用高版本的Python并且可以不在节点上安装Python3环境呢？</p>
<p><strong>办法是有的！</strong></p>
<p><strong>我们可以通过将Python虚拟环境打包，将其上传到HDFS上，当提交我们的任务时，Spark的worker节点会自动加载该虚拟环境，使用其中的Python环境运行我们的<code class="docutils literal notranslate"><span class="pre">.py</span></code>程序</strong></p>
<section id="id3">
<h3><span class="section-number">43.3.1. </span>先决条件<a class="headerlink" href="#id3" title="永久链接至标题"></a></h3>
<p>将我们的Python3虚拟环境打包，使用<code class="docutils literal notranslate"><span class="pre">.zip</span></code>的格式上传到HDFS，推荐使用Conda打包，此步骤可以去百度搜索看看。</p>
<ul class="simple">
<li><p>1.以miniconda为例</p></li>
<li><p>安装好miniconda</p></li>
<li><p>使用conda create -n $myenv_name python=3.6 并用python=3.6来指定对应python环境的版本</p></li>
<li><p>在创建好的环境(在miniconda 安装目录的env文件夹下面)使用pip 安装好需要的包</p></li>
<li><p>使用zip 命令将 env文件夹下面对应$myenv_name的文件夹打包 该文件夹包含了所有的 环境所需的文件 打包后 发送到集群的各台机器上即可工作</p></li>
<li><p>在spark提交命令中 使用 –conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./PyEnv/py36/bin/python来指定对应的python指定文件 PyEnv 是将压缩包解压后的目录py36是$myenv_name python是对应环境下面的python可执行文件</p></li>
</ul>
</section>
<section id="id4">
<h3><span class="section-number">43.3.2. </span>提交任务<a class="headerlink" href="#id4" title="永久链接至标题"></a></h3>
<p>完整的提交命令如下:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>spark-submit <span class="se">\</span>
--master yarn <span class="se">\</span>
--deploy-mode cluster <span class="se">\</span>
--driver-memory 1g <span class="se">\</span>
--driver-cores <span class="m">2</span> <span class="se">\</span>
--num-executors <span class="m">3</span> <span class="se">\</span>
--executor-memory 5G <span class="se">\</span>
--conf spark.executor.pyspark.memory<span class="o">=</span>2G <span class="se">\</span>
--executor-cores <span class="m">4</span> <span class="se">\</span>
--conf spark.yarn.maxAppAttempts<span class="o">=</span><span class="m">1</span> <span class="se">\</span>
--conf spark.driver.maxResultSize<span class="o">=</span>2G <span class="se">\</span>
--conf spark.dynamicAllocation.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
--archives hdfs://nameservice1/tmp/pyenv/p36.zip#PyEnv <span class="se">\</span>
--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
--conf spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
--conf spark.executorEnv.PYSPARK_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
--conf spark.executorEnv.PYSPARK_DRIVER_PYTHON<span class="o">=</span>PyEnv/p36/bin/python <span class="se">\</span>
./sample.py 
</pre></div>
</div>
<p>其中<code class="docutils literal notranslate"><span class="pre">sample.py</span></code>的内容如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;PySparkOnYarn&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT &#39;AAA&#39; AS AHA&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3><span class="section-number">43.3.3. </span>命令说明<a class="headerlink" href="#id5" title="永久链接至标题"></a></h3>
<ul>
<li><p>归档文件<code class="docutils literal notranslate"><span class="pre">--archives</span></code></p>
<blockquote>
<div><p>–archives ./py36.zip#PyEnv
这个参数的意思是将压缩包 zip文件分发到集群上,将压缩文件解压,解压后的文件全部放在 # 后面指定的文件夹下 PyEnv 这个目录下面,也就是说在代码中可以使用 PyEnv/xxx.txt 来读取压缩包中的xxx.txt文件,多个压缩文件使用逗号分隔符分割,如果压缩包里面有一个跟文件夹root_dir/,那么解压后将变成 PyEnv/root_dir</p>
</div></blockquote>
</li>
<li><p>一般资源文件<code class="docutils literal notranslate"><span class="pre">--files</span></code></p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">--files</span> <span class="pre">./config.json#my_config.json</span></code>
这个参数的意思是 将<code class="docutils literal notranslate"><span class="pre">config.json</span></code> 文件分发到集群上 之后使用<code class="docutils literal notranslate"><span class="pre">my_config.json</span></code>来访问这个文件 <code class="docutils literal notranslate"><span class="pre">#</span></code>后面相当于是文件的别名 文件表示使用逗号分隔符分割</p>
</div></blockquote>
</li>
<li><p>代码文件<code class="docutils literal notranslate"><span class="pre">--py-files</span></code></p>
<blockquote>
<div><p>有时候提交的pyspark python脚本文件不止一个 互相之间要引用 这时要
例如
–py-files ./feature.py
这个参数的意思是 将feature.py 文件分发到集群上 放在和主脚本在一起的代码目录下 这样就可以引用feature.py中的函数了 文件表示使用逗号分隔符分割</p>
</div></blockquote>
</li>
<li><p>下面这三个命令都是将Driver和Worker节点的Python环境设置为我们手动打包上传的Python环境</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">yarn</span><span class="o">.</span><span class="n">appMasterEnv</span><span class="o">.</span><span class="n">PYSPARK_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
<span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">yarn</span><span class="o">.</span><span class="n">appMasterEnv</span><span class="o">.</span><span class="n">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
<span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">executorEnv</span><span class="o">.</span><span class="n">PYSPARK_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
<span class="o">--</span><span class="n">conf</span> <span class="n">spark</span><span class="o">.</span><span class="n">executorEnv</span><span class="o">.</span><span class="n">PYSPARK_DRIVER_PYTHON</span><span class="o">=</span><span class="n">PyEnv</span><span class="o">/</span><span class="n">p36</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">python</span> \
</pre></div>
</div>
</section>
</section>
<section id="run">
<h2><span class="section-number">43.4. </span>RUN起来！<a class="headerlink" href="#run" title="永久链接至标题"></a></h2>
<p>提交</p>
<p><img alt="image-20210809235223787" src="../_images/image-20210809235223787.png" /></p>
<p><img alt="image-20210809235343512" src="../_images/image-20210809235343512.png" /></p>
<p><img alt="image-20210809235407073" src="../_images/image-20210809235407073.png" /></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="%5BPySpark%5DPySpark.html" class="btn btn-neutral float-left" title="42. [Pyspark]PySpark" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="%5BSQL%5DSQLIn%26NotIn.html" class="btn btn-neutral float-right" title="44. [SQL]IN OR NOT IN , IS A PROBLEM" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2020-2022, roohom.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>