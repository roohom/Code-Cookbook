<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>2. Apache Flume &mdash; Code-Cookbook 0.2 文档</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/translations.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="3. Flink" href="Flink.html" />
    <link rel="prev" title="1. Apache Druid" href="Apache%20Druid.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Code-Cookbook
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">大数据</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Bigdata/index.html">Bigdata</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Bigdata Tools</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Apache%20Druid.html">1. Apache Druid</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">2. Apache Flume</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">2.1. 概述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id2">2.2. 组件架构</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#flume">2.2.1. Flume事务</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id6">2.3. Flume 安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">2.4. 案例</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">2.4.1. 入门案例</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hdfs">2.4.2. 采集数据到HDFS</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kafka">2.4.3. 采集数据到Kafka</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Flink.html">3. Flink</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hadoop%E6%90%AD%E5%BB%BA%E6%80%BB%E4%BD%93%E6%AD%A5%E9%AA%A4.html">4. Hadoop搭建总体步骤</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hbase.html">5. Hbase</a></li>
<li class="toctree-l2"><a class="reference internal" href="Hive%E6%95%B0%E4%BB%93.html">6. Hive</a></li>
<li class="toctree-l2"><a class="reference internal" href="Kafka.html">7. Kafka</a></li>
<li class="toctree-l2"><a class="reference internal" href="Kudu.html">8. Kudu</a></li>
<li class="toctree-l2"><a class="reference internal" href="Kylin.html">9. Kylin</a></li>
<li class="toctree-l2"><a class="reference internal" href="Redis.html">10. Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="Spark.html">11. Spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="SparkCore.html">12. Spark Core</a></li>
<li class="toctree-l2"><a class="reference internal" href="SparkSQL.html">13. Spark SQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="SparkStreaming.html">14. Spark Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="StructuredStreaming.html">15. Structured Streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="Zookeeper.html">16. Zookeeper</a></li>
<li class="toctree-l2"><a class="reference internal" href="ZookeeperAndHadoop.html">17. ZookeeperAndHadoop</a></li>
<li class="toctree-l2"><a class="reference internal" href="%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BD%AF%E4%BB%B6%E5%90%AF%E5%8A%A8%E6%8C%87%E5%8D%97.html">18. 常用软件梳理</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">博客</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Blog%20Here/index.html">Blogs</a></li>
</ul>
<p class="caption"><span class="caption-text">大数据辅助工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Auxiliary%20tools/index.html">Auxiliary tools</a></li>
</ul>
<p class="caption"><span class="caption-text">SQL相关</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../SQL/index.html">SQL</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Code-Cookbook</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Bigdata Tools</a> &raquo;</li>
      <li><span class="section-number">2. </span>Apache Flume</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Bigdata Tools/Apache Flume.md.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="apache-flume">
<h1><span class="section-number">2. </span>Apache Flume<a class="headerlink" href="#apache-flume" title="永久链接至标题"></a></h1>
<section id="id1">
<h2><span class="section-number">2.1. </span>概述<a class="headerlink" href="#id1" title="永久链接至标题"></a></h2>
<blockquote>
<div><p>官网:http://flume.apache.org/</p>
</div></blockquote>
<blockquote>
<div><p>Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的工具。基于流式架构，容错性强，也很灵活简单。
Flume可以采集文件，socket数据包、文件、文件夹、kafka等各种形式源数据，又可以将采集到的数据(下沉sink)输出到HDFS、hbase、hive、kafka等众多外部存储系统中，一般的采集需求，通过对flume的简单配置即可实现
Flume针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景。</p>
</div></blockquote>
<ul class="simple">
<li><p>Flume是一个海量数据采集的软件。</p></li>
<li><p>Flume是一款来自于apache  java语言软件。</p></li>
<li><p>Flume身世</p>
<ul>
<li><p>0.9- 属于Cloudera  叫做flume-og</p></li>
<li><p>1.0+ 属于apache  叫做<strong>flume-ng</strong></p></li>
</ul>
</li>
</ul>
</section>
<section id="id2">
<h2><span class="section-number">2.2. </span>组件架构<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<p>1、Flume分布式系统中最核心的角色是agent，agent 本身是一个 Java 进程，一般运行在日志收集节点。flume采集系统就是由一个个agent所连接起来形成。
2、每一个agent相当于一个数据传递员，内部有三个组件：
a)Source：采集组件，用于跟数据源对接，以获取数据
b)Sink：下沉组件，用于往下一级agent传递数据或者往最终存储系统传递数据
c)Channel：传输通道组件，用于从source将数据传递到sink</p>
<p>简单结构</p>
<p><img alt="image-20201024152821463" src="../_images/image-20201024152821463.png" /></p>
<blockquote>
<div><p>Source 到 Channel 到 Sink之间传递数据的形式是Event事件；Event事件是一个数据流单元</p>
</div></blockquote>
<p>复杂结构</p>
<p>多级agent之间串联</p>
<p><img alt="image-20201024192847583" src="../_images/image-20201024192847583.png" /></p>
<ul>
<li><p>部署架构</p>
<ul>
<li><p>单agent架构</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">适合简单业务场景</span>  <span class="n">只需要部署一个agent进程即可</span>
</pre></div>
</div>
</li>
<li><p>多agent级联（串联）</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>适合复杂业务场景  在此场景下 各个agent之间没有地位区别 大家都一样。没有主从之分。
因为在多台机器部署的 也称之为分布式架构。
</pre></div>
</div>
</li>
</ul>
</li>
<li><p>数据流程</p></li>
</ul>
<p>Flume的一般流程是这样的:</p>
<p>source监控某个文件或数据流，数据源产生新的数据，拿到该数据后，将数据封装在一个Event中，并发送到channel后提交，channel队列先进先出，sink去channel队列中拉取数据，然后写入到HDFS/Kafka/或者其他的数据源,甚至是下一个Agent的Source。</p>
<ul>
<li><p>组件</p>
<ul>
<li><p>source</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>对接各个不同的数据源。 采集数据。
</pre></div>
</div>
</li>
</ul>
<p>​       常用的Source有:</p>
<p>​     1) exec：可通过tail -f命令去tail一个文件，然后实时同步日志到sink</p>
<p>​     2) spooldir：可监听一个目录，同步目录中的新文件到sink,被同步完的文件可被立即删除或被打上标记。       适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步。</p>
<p>​     3) taildir：可实时监控一批文件，并记录每个文件最新消费位置，agent进程重启后不会有重复消费的问题</p>
<p>​     4) 支持自定义</p>
<ul>
<li><p>channel</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>就是source和sink之间缓存数据的通道。
</pre></div>
</div>
</li>
</ul>
<p>​       Channel是Agent 内部的数据传输通道，用于从 source 将数据传递到 sink；用于桥接Sources和Sinks，      类似于一个队列/缓存。Channel分为:</p>
<p>​      1) Memory Channel是基于内存的,速度快</p>
<p>​      2) File Channel是基于文件的,速度慢,因为会将所有事件写到磁盘,但数据更安全</p>
<ul>
<li><p>sink</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">对接各个不同下沉地</span><span class="p">(</span><span class="n">目的地</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<p>​       Sink是下沉地/目的地，采集数据的传送目的地，用于从Channel收集数据，将数据写到目标源,Sink分为:</p>
<p>​      1) 可以是HDFS、HBase、Kafka等</p>
<p>​      2) 也可以是下一个 FlumeAgent的Source</p>
<p>​      3) 支持自定义</p>
<ul class="simple">
<li><p>结论：上述3个组件就组成了flume的一个java进程。该进程的名字叫做agent。</p></li>
</ul>
</li>
<li><p>Event</p>
<ul>
<li><p>event是flume内部最小的数据单元。</p></li>
<li><p>flume采集的数据都是以event形式存在的。类似于数据包。</p></li>
<li><p>event分为event head /event body 数据都是存储在body中。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">Event</span><span class="p">:</span> <span class="p">{</span> <span class="n">headers</span><span class="p">:{}</span> <span class="n">body</span><span class="p">:</span> <span class="mi">6</span><span class="n">E</span> <span class="mi">69</span> <span class="mi">68</span> <span class="mi">61</span> <span class="mi">6</span><span class="n">F</span> <span class="mi">0</span><span class="n">D</span>                 <span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<section id="flume">
<h3><span class="section-number">2.2.1. </span>Flume事务<a class="headerlink" href="#flume" title="永久链接至标题"></a></h3>
<p><img alt="FlumeTransaction" src="../_images/FlumeTransaction.svg" /></p>
<section id="id3">
<h4><span class="section-number">2.2.1.1. </span>数据传输的三大步骤<a class="headerlink" href="#id3" title="永久链接至标题"></a></h4>
<ul class="simple">
<li><p>Source从数据源读取数据</p></li>
<li><p>Source将数据<strong>推送</strong>进入Channel</p></li>
<li><p>Sink从Channel中<strong>拉取</strong>数据</p></li>
</ul>
</section>
<section id="id4">
<h4><span class="section-number">2.2.1.2. </span>Flume如何实现传输数据的完整性、可靠性？<a class="headerlink" href="#id4" title="永久链接至标题"></a></h4>
<ul class="simple">
<li><p>数据为什么会丢失（没有事务机制的情况下）？</p>
<ul>
<li><p>Channel是被动的，Source将数据主动推送给Channel，而Sink主动从Channel拉取数据（Take）</p></li>
<li><p>一般Channel使用MemoryChannel，这样速度更快（FileChannel更安全但是速度慢），但是由于是基于内存，agent宕机的情况下可能导致内存中的数据丢失</p></li>
<li><p>Source端。</p></li>
</ul>
</li>
</ul>
</section>
<section id="id5">
<h4><span class="section-number">2.2.1.3. </span>Flume的事务机制<a class="headerlink" href="#id5" title="永久链接至标题"></a></h4>
<section id="put">
<h5><span class="section-number">2.2.1.3.1. </span>Put事务<a class="headerlink" href="#put" title="永久链接至标题"></a></h5>
<blockquote>
<div><p>顺利的情况下：</p>
<p>Source采集数据调用duPut方法将一批数据（Event）封装在putList中，这批数据成功放入putList中之后，就会调用doCommit方法，将所有的Event放入到Channel中，成功放入就会清空putList。</p>
<p>问题：</p>
<p>第一种：</p>
<ul class="simple">
<li><p>如果Sink取出数据的速度过慢，而source放入数据过快，就会造成Channel中数据积压，这个时候putList中的数据就会放不进去，可是已经doCommit了，putList数据丢失了</p></li>
<li><p>解决：调用doRollback方法：</p>
<ul>
<li><p>将putList清空，抛出ChannelException</p></li>
<li><p>这个时候Source就会catch到doRollback的异常，Source就会将之前的一批数据重新采集，采集完成之后重新进行事务流程</p></li>
</ul>
</li>
</ul>
<p>第二种：</p>
<ul class="simple">
<li><p>如果Source采集数据使用的是tailDir source，由于某种情况下，监听分源目录被删除了，也会出现问题</p></li>
<li><p>解决：调用doRollback来进行事务回滚</p></li>
</ul>
</div></blockquote>
</section>
<section id="take">
<h5><span class="section-number">2.2.1.3.2. </span>Take事务<a class="headerlink" href="#take" title="永久链接至标题"></a></h5>
<blockquote>
<div><p>顺利的情况下：</p>
<p>doTake方法会将Channel中的数据剪切到takeList中，然后等到takeList满后会调用doCommit方法将数据写入目的地，调用doCommit时会进行将数据写入目的地之后再清空takeList</p>
<p>问题：</p>
<ul class="simple">
<li><p>如果出现网络原因导致数据写入到目的地时传输失败了，这个时候如果不进行回滚而置之不理就会导致数据丢失</p></li>
<li><p>解决：调用doRollback方法来进行回滚，takeList中存有备份数据，takeList中的数据就会原封不动地返还给Channel</p></li>
<li><p>新的问题：如果在往目的地Sink数据的时候，刚好Sink“一半”的时候目的机宕机了，在回滚的时候takeList还是将全部数据原封不动返还给Channel，当目的机重新启动上线的时候，再进行Sink操作，这个时候数据就会重复了。<strong>所以从某种程度上来说，使用Flume采集数据不会丢失数据反而会使得数据重复。</strong></p></li>
</ul>
</div></blockquote>
</section>
</section>
</section>
</section>
<section id="id6">
<h2><span class="section-number">2.3. </span>Flume 安装<a class="headerlink" href="#id6" title="永久链接至标题"></a></h2>
<ul>
<li><p>提取将JDK配置好</p></li>
<li><p>上传安装包进行解压</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>tar -zxvf flume-ng-1.6.0-cdh5.14.0.tar.gz -C /export/servers/
</pre></div>
</div>
</li>
<li><p>配置文件</p>
<p>cd  /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cp</span>  <span class="n">flume</span><span class="o">-</span><span class="n">env</span><span class="o">.</span><span class="n">sh</span><span class="o">.</span><span class="n">template</span> <span class="n">flume</span><span class="o">-</span><span class="n">env</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>vim flume-env.sh</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">JAVA_HOME</span><span class="o">=</span>/export/servers/jdk1.8.0_141
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>​    配置成自己得JDK安装版本和安装目录</p>
</div></blockquote>
</section>
<section id="id7">
<h2><span class="section-number">2.4. </span>案例<a class="headerlink" href="#id7" title="永久链接至标题"></a></h2>
<section id="id8">
<h3><span class="section-number">2.4.1. </span>入门案例<a class="headerlink" href="#id8" title="永久链接至标题"></a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>需求：采集日志文件 如果有数据发送 采集数据打印到控制台。
</pre></div>
</div>
<section id="id9">
<h4><span class="section-number">2.4.1.1. </span>配置文件编写<a class="headerlink" href="#id9" title="永久链接至标题"></a></h4>
<ul>
<li><p>所谓的采集方案指的就是根据业务需求 确定3个组件的类型和参数。 flume只有根据采集方案文件才指的如何工作。</p></li>
<li><p>确定3个组件</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>source: TAILDIR  读取文件

channel:memory channel 缓存在内存中

sink: logger 把数据打印到控制台

基于上述3个类型组件 编写采集方案。
</pre></div>
</div>
</li>
</ul>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf/</p>
<p>vim  console-logger.conf</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="c"># Name the components on this agent</span>
<span class="c"># 先定义这个agent中各组件的名字 a1</span>
<span class="c"># 再给3个组件 分别起名字</span>
<span class="na">a1.sources</span> <span class="o">=</span> <span class="s">r1</span>
<span class="na">a1.sinks</span> <span class="o">=</span> <span class="s">k1</span>
<span class="na">a1.channels</span> <span class="o">=</span> <span class="s">c1</span>

<span class="c"># Describe/configure the source</span>
<span class="c"># 描述和配置source组件：r1  </span>
<span class="na">a1.sources.r1.type</span> <span class="o">=</span> <span class="s">TAILDIR</span>
<span class="na">a1.sources.r1.filegroups</span> <span class="o">=</span> <span class="s">f1</span>
<span class="na">a1.sources.r1.filegroups.f1</span> <span class="o">=</span> <span class="s">/export/servers/tmp/flume/orderinfo.log</span>

<span class="c"># Describe the sink</span>
<span class="c"># 描述和配置source组件：r1</span>
<span class="na">a1.sinks.k1.type</span> <span class="o">=</span> <span class="s">logger</span>

<span class="c"># Use a channel which buffers events in memory</span>
<span class="c"># 描述和配置channel组件，此处使用是内存缓存的方式</span>
<span class="na">a1.channels.c1.type</span> <span class="o">=</span> <span class="s">memory</span>
<span class="na">a1.channels.c1.capacity</span> <span class="o">=</span> <span class="s">1000</span>
<span class="na">a1.channels.c1.transactionCapacity</span> <span class="o">=</span> <span class="s">100</span>

<span class="c"># Bind the source and sink to the channel</span>
<span class="c"># 描述和配置source  channel   sink之间的连接关系</span>
<span class="na">a1.sources.r1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="na">a1.sinks.k1.channel</span> <span class="o">=</span> <span class="s">c1</span>
</pre></div>
</div>
<blockquote>
<div><p>各组件得名称可以自定义</p>
</div></blockquote>
</section>
<section id="id10">
<h4><span class="section-number">2.4.1.2. </span>数据源模拟<a class="headerlink" href="#id10" title="永久链接至标题"></a></h4>
<p>模拟日志发送数据</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">echo</span> <span class="s2">&quot;订单金额：100&quot;</span> &gt;&gt; /export/servers/tmp/flume/orderinfo.log
</pre></div>
</div>
</section>
<section id="id11">
<h4><span class="section-number">2.4.1.3. </span>Flume启动命令<a class="headerlink" href="#id11" title="永久链接至标题"></a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1">#完整版命令</span>
bin/flume-ng agent --conf conf --conf-file conf/console-logger.conf --name a1 -Dflume.root.logger<span class="o">=</span>INFO,console

<span class="c1">#精简版命令</span>
bin/flume-ng agent -c ./conf -f ./conf/console-logger.conf  -n a1 -Dflume.root.logger<span class="o">=</span>INFO,console


<span class="c1">#bin/flume-ng agent  固定搭配</span>
<span class="c1">#--conf（-c）</span>
	指定默认的配置文件路径  要求改路径下 必须有两个文件：flume-env.sh log4j.properties
<span class="c1">#--conf-file  （-f）</span>
	指定采集方案文件路径
<span class="c1">#--name	 指定agent的名字 进程名称 （-n）</span>
	该名称可以随便起 但是要保证和采集方案中一致
<span class="c1">#-Dflume.root.logger=INFO,console</span>
	开启日志 打印更详细的信息 在开发中建议打开
</pre></div>
</div>
<blockquote>
<div><p>–name	 指定agent的名字表示进程名称，一定</p>
</div></blockquote>
</section>
</section>
<section id="hdfs">
<h3><span class="section-number">2.4.2. </span>采集数据到HDFS<a class="headerlink" href="#hdfs" title="永久链接至标题"></a></h3>
<ul>
<li><p>案例1</p>
<ul>
<li><p>需求：某目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到 HDFS中去</p></li>
<li><p>确定agent组件</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">source</span><span class="p">:</span> <span class="n">TAILDIR</span>
<span class="n">channel</span><span class="p">:</span> <span class="n">memory</span> <span class="n">channel</span>
<span class="n">sink</span><span class="p">:</span>  <span class="n">HDFS</span> <span class="n">sink</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
<section id="id12">
<h4><span class="section-number">2.4.2.1. </span>配置文件编写<a class="headerlink" href="#id12" title="永久链接至标题"></a></h4>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<p>vim fileToHdfs.conf</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="c">#为我们的source channel  sink起名</span>
<span class="na">a1.sources</span> <span class="o">=</span> <span class="s">r1</span>
<span class="na">a1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="na">a1.sinks</span> <span class="o">=</span> <span class="s">s1</span>
<span class="c">#指定我们的source收集到的数据发送到哪个管道</span>
<span class="na">a1.sources.r1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="c">#指定我们的source数据收集策略</span>
<span class="na">a1.sources.r1.type</span> <span class="o">=</span> <span class="s">TAILDIR</span>
<span class="na">a1.sources.r1.filegroups</span> <span class="o">=</span> <span class="s">f1</span>
<span class="na">a1.sources.r1.filegroups.f1</span> <span class="o">=</span> <span class="s">/export/servers/tmp/flume/orderinfo.log</span>

<span class="c">#指定我们的channel为memory,即表示所有的数据都装进memory当中</span>
<span class="na">a1.channels.c1.type</span> <span class="o">=</span> <span class="s">memory</span>
<span class="c">#指定我们的sink为kafka  sink，并指定我们的sink从哪个channel当中读取数据</span>
<span class="na">a1.sinks.s1.channel</span> <span class="o">=</span> <span class="s">c1</span>
<span class="na">a1.sinks.s1.type</span><span class="o">=</span><span class="s">hdfs</span>
<span class="na">a1.sinks.s1.hdfs.path</span><span class="o">=</span><span class="s">hdfs://node1:8020/tmp/flume</span>
<span class="na">a1.sinks.s1.hdfs.fileType</span><span class="o">=</span><span class="s">DataStream</span>
</pre></div>
</div>
</section>
<section id="id13">
<h4><span class="section-number">2.4.2.2. </span>数据源模拟<a class="headerlink" href="#id13" title="永久链接至标题"></a></h4>
<p>模拟日志发送数据</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">echo</span> <span class="s2">&quot;订单金额：100&quot;</span> &gt;&gt; /export/servers/tmp/flume/orderinfo.log
</pre></div>
</div>
</section>
<section id="id14">
<h4><span class="section-number">2.4.2.3. </span>Flume启动命令<a class="headerlink" href="#id14" title="永久链接至标题"></a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1">#精简版命令</span>
bin/flume-ng agent -c ./conf -f ./conf/fileToHdfs.conf  -n a1 -Dflume.root.logger<span class="o">=</span>INFO,console
</pre></div>
</div>
</section>
<section id="id15">
<h4><span class="section-number">2.4.2.4. </span>优化配置<a class="headerlink" href="#id15" title="永久链接至标题"></a></h4>
<ul>
<li><p>配置参数介绍</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1">#roll 控制文件以何种形式触发滚动 写入新文件</span>
a1.sinks.k1.hdfs.rollInterval <span class="o">=</span> <span class="m">3</span>  <span class="c1">#以时间间隔控制滚动  默认30 s</span>
a1.sinks.k1.hdfs.rollSize <span class="o">=</span> <span class="m">20</span>    <span class="c1">#以文件大小控制滚动  默认1024 bytes </span>
a1.sinks.k1.hdfs.rollCount <span class="o">=</span> <span class="m">5</span>    <span class="c1">#以event数量控制滚动  默认 10 个</span>

<span class="c1">#上述三个都配置的情况下 如果滚动？  谁先满足 谁触发滚动。</span>
<span class="c1">#如果不想以某个属性滚动。 就把该属性设置为0  禁用该属性滚动。</span>

<span class="c1">#注意事项  如果滚动条件设置不合理 会频繁触发文件切换 会造成大量小文件产生</span>
<span class="c1">#在实际开发中 避免小文件产生  最喜欢根据128M大小进行滚动  134217728</span>


<span class="c1">#round 是否开启时间上的舍弃  通俗解释：多少时间切换新的文件夹</span>
a1.sinks.k1.hdfs.round <span class="o">=</span> <span class="nb">true</span>
a1.sinks.k1.hdfs.roundValue <span class="o">=</span> <span class="m">10</span>
a1.sinks.k1.hdfs.roundUnit <span class="o">=</span> minute
</pre></div>
</div>
<ul>
<li><p>注意事项  因为在flume中涉及到了动态提取时间**的功能  需要做下面两件事中任一即可：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">flume</span><span class="o">/</span><span class="n">events</span><span class="o">/%</span><span class="n">y</span><span class="o">-%</span><span class="n">m</span><span class="o">-%</span><span class="n">d</span><span class="o">/%</span><span class="n">H</span><span class="o">%</span><span class="n">M</span><span class="o">/</span>
</pre></div>
</div>
<ul>
<li><p>开启使用本地时间戳</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">a1</span><span class="o">.</span><span class="n">sinks</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">hdfs</span><span class="o">.</span><span class="n">useLocalTimeStamp</span> <span class="o">=</span> <span class="n">true</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
<li><p>完整配置文件</p></li>
</ul>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<p>vim fileToHdfs2.conf</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">a1.sources</span> <span class="o">=</span> <span class="s">r1</span>
<span class="na">a1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="na">a1.sinks</span> <span class="o">=</span> <span class="s">s1</span>
<span class="c">#指定channel</span>
<span class="na">a1.sources.r1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="c">#指定我们的source数据收集策略</span>
<span class="na">a1.sources.r1.type</span> <span class="o">=</span> <span class="s">exec</span>
<span class="na">a1.sources.r1.command</span> <span class="o">=</span> <span class="s">tail -f  /export/servers/tmp/flume/test.log</span>

<span class="c">#指定我们的channel为memory,即表示所有的数据都装进memory当中</span>
<span class="na">a1.channels.c1.type</span> <span class="o">=</span> <span class="s">memory</span>
<span class="c">#指定我们的sink到s1，并指定我们的sink从c1当中读取数据</span>
<span class="na">a1.sinks.s1.channel</span> <span class="o">=</span> <span class="s">c1</span>

<span class="na">a1.sinks.s1.type</span><span class="o">=</span><span class="s">hdfs</span>
<span class="na">a1.sinks.s1.hdfs.path</span><span class="o">=</span><span class="s">hdfs://node1:8020/tmp/flume/%y-%m-%d/%H-%M/</span>
<span class="na">a1.sinks.s1.hdfs.fileType</span><span class="o">=</span><span class="s">DataStream</span>

<span class="na">a1.sinks.s1.hdfs.rollInterval</span> <span class="o">=</span> <span class="s">3</span>
<span class="na">a1.sinks.s1.hdfs.rollSize</span> <span class="o">=</span> <span class="s">20</span>
<span class="na">a1.sinks.s1.hdfs.rollCount</span> <span class="o">=</span> <span class="s">5</span>
<span class="na">a1.sinks.s1.hdfs.round</span> <span class="o">=</span> <span class="s">true</span>
<span class="na">a1.sinks.s1.hdfs.roundValue</span> <span class="o">=</span> <span class="s">10</span>
<span class="na">a1.sinks.s1.hdfs.roundUnit</span> <span class="o">=</span> <span class="s">minute</span>
<span class="na">a1.sinks.s1.hdfs.useLocalTimeStamp</span> <span class="o">=</span> <span class="s">true</span>
<span class="na">a1.sinks.s1.hdfs.filePrefix</span> <span class="o">=</span> <span class="s">test</span>
<span class="na">a1.sinks.s1.hdfs.fileSuffix</span> <span class="o">=</span> <span class="s">log                    </span>
</pre></div>
</div>
<ul>
<li><p>模拟日志增量数据</p>
<ul>
<li><p>日志内容不断增加，需要把采集数据追到日志文件中，并实时写入到 hdfs</p></li>
<li><p>确定3个组件</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>source:  exec   #支持在flume中运行shell命令 把命令执行的结果作为数据源进行采集。
		 shell：tail -f 文件路径
channel: memory channel  基于内存缓存数据
sink: hdfs sink
</pre></div>
</div>
</li>
<li><p>编写增量日志脚本</p>
<p>cd /export/servers/tmp/flume</p>
</li>
</ul>
<p>​        vim shell_log.sh</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> true<span class="p">;</span><span class="k">do</span> date &gt;&gt; /export/servers/tmp/flume/test.log<span class="p">;</span>sleep <span class="m">0</span>.5<span class="p">;</span><span class="k">done</span>



<span class="c1">#!/bin/bash</span>
<span class="k">while</span> <span class="nb">true</span>
<span class="k">do</span>
 date &gt;&gt;  /export/servers/tmp/flume/test.log
 sleep <span class="m">0</span>.5
<span class="k">done</span>
</pre></div>
</div>
</li>
</ul>
<blockquote>
<div><p>sh脚本赋权限：chmod 755 shell_log.sh</p>
</div></blockquote>
<p>执行脚本：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sh  shell_log.sh
</pre></div>
</div>
<p>查看日志：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>tail -f /export/servers/tmp/flume/test.log 
</pre></div>
</div>
<p>启动flume命令：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bin/flume-ng agent -c ./conf -f ./conf/fileToHdfs2.conf  -n a1 -Dflume.root.logger<span class="o">=</span>INFO,console
</pre></div>
</div>
</section>
</section>
<section id="kafka">
<h3><span class="section-number">2.4.3. </span>采集数据到Kafka<a class="headerlink" href="#kafka" title="永久链接至标题"></a></h3>
<section id="id16">
<h4><span class="section-number">2.4.3.1. </span>配置文件编写<a class="headerlink" href="#id16" title="永久链接至标题"></a></h4>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<p>vim fileToKafka.conf</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="c">#为我们的source channel  sink起名</span>
<span class="na">a1.sources</span> <span class="o">=</span> <span class="s">r1</span>
<span class="na">a1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="na">a1.sinks</span> <span class="o">=</span> <span class="s">k1</span>
<span class="c">#指定我们的source收集到的数据发送到哪个管道</span>
<span class="na">a1.sources.r1.channels</span> <span class="o">=</span> <span class="s">c1</span>
<span class="c">#指定我们的source数据收集策略</span>
<span class="na">a1.sources.r1.type</span> <span class="o">=</span> <span class="s">TAILDIR</span>
<span class="na">a1.sources.r1.filegroups</span> <span class="o">=</span> <span class="s">f1</span>
<span class="na">a1.sources.r1.filegroups.f1</span> <span class="o">=</span> <span class="s">/export/servers/tmp/flume/orderinfo.log</span>

<span class="c">#指定我们的channel为memory,即表示所有的数据都装进memory当中</span>
<span class="na">a1.channels.c1.type</span> <span class="o">=</span> <span class="s">memory</span>
<span class="c">#指定我们的sink为kafka  sink，并指定我们的sink从哪个channel当中读取数据</span>
<span class="na">a1.sinks.k1.channel</span> <span class="o">=</span> <span class="s">c1</span>
<span class="na">a1.sinks.k1.type</span> <span class="o">=</span> <span class="s">org.apache.flume.sink.kafka.KafkaSink</span>
<span class="na">a1.sinks.k1.kafka.topic</span> <span class="o">=</span> <span class="s">test2</span>
<span class="na">a1.sinks.k1.kafka.bootstrap.servers</span> <span class="o">=</span> <span class="s">node1:9092,node2:9092,node3:9092</span>
<span class="na">a1.sinks.k1.kafka.flumeBatchSize</span> <span class="o">=</span> <span class="s">20</span>
<span class="na">a1.sinks.k1.kafka.producer.acks</span> <span class="o">=</span> <span class="s">1</span>
</pre></div>
</div>
</section>
<section id="id17">
<h4><span class="section-number">2.4.3.2. </span>数据源模拟<a class="headerlink" href="#id17" title="永久链接至标题"></a></h4>
<p>模拟日志发送数据</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">echo</span> <span class="s2">&quot;订单金额：100&quot;</span> &gt;&gt; /export/servers/tmp/flume/orderinfo.log
</pre></div>
</div>
</section>
<section id="id18">
<h4><span class="section-number">2.4.3.3. </span>Flume启动命令<a class="headerlink" href="#id18" title="永久链接至标题"></a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1">#精简版命令</span>
bin/flume-ng agent -c ./conf -f ./conf/fileToKafka.conf  -n a1 -Dflume.root.logger<span class="o">=</span>INFO,console
</pre></div>
</div>
</section>
<section id="id19">
<h4><span class="section-number">2.4.3.4. </span>kafka消费命令<a class="headerlink" href="#id19" title="永久链接至标题"></a></h4>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">bin</span><span class="o">/</span><span class="n">kafka</span><span class="o">-</span><span class="n">console</span><span class="o">-</span><span class="n">consumer</span><span class="o">.</span><span class="n">sh</span> <span class="o">--</span><span class="n">bootstrap</span><span class="o">-</span><span class="n">server</span> <span class="n">node1</span><span class="p">:</span><span class="mi">9092</span><span class="p">,</span><span class="n">node2</span><span class="p">:</span><span class="mi">9092</span><span class="p">,</span><span class="n">node3</span><span class="p">:</span><span class="mi">9092</span> <span class="o">--</span><span class="n">topic</span> <span class="n">test2</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Apache%20Druid.html" class="btn btn-neutral float-left" title="1. Apache Druid" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="Flink.html" class="btn btn-neutral float-right" title="3. Flink" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2020-2022, roohom.</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a>开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>